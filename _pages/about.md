---
permalink: /
title: "Welcome to my Homepage ü§ó"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

[quick life update] I've recently joined Amazon in Seattle, WA as an Applied Scientist.

I obtained my Ph.D. at The Ohio State University's department of Electrical and Computer Engineering, under the supervision of [Prof. Yingbin Liang](https://sites.google.com/view/yingbinliang/home). 
Before joining OSU, I obtained my M.Sc. in Machine Learning and Intelligent Systems at 
Beijing University of Aeronautics and Astronautics (Beihang University), and did my undergraduate studies in Electrical Engineering at Ecole Polytechnique de Thies, Senegal. 

## Research 
My research interests are mainly about optimization methods for modern Machine Learning (ML), robust ML, and Deep Learning Theory. 
On the theoretical side, I am interested in building new frameworks, especially through the lens of bilevel optimization, 
that capture modern ML applications such as Meta Learning, Adversarial Training, Hyperparameter Optimization, etc. 
On the practical side, I aim to design new algorithms with provable guarantees to tackle these problems as well as develop their practical and efficient implementations. 
More recently, I mainly focus on optimization for task-specific adaptation of large language models (LLMs), either via direct finetuning of the parameters (when access is allowed) or optimizing the instructions for blackbox LLMs. 
I'm affiliated with the [NSF AI Institute for Future Edge Networks and Distributed Intelligence (AI-EDGE)](https://aiedge.osu.edu/). 

## News (will update soon for last two years!)

[//]: # (August 2023 - started here, [11/23] ) 
- [Jan 2024] Will be joining IBM Research in New York to work on curriculum learning for foundation models! 
- [Jan 2024] New paper accepted: our [doubly-robust training](https://arxiv.org/abs/2308.00311) work is accepted by ICLR 2024! 
- New paper accepted: our work on [online bilevel optimization](https://arxiv.org/abs/2308.03811) has been accepted by NeurIPS 2023! 
- New paper accepted: our [dynamic online meta-learning paper](https://arxiv.org/abs/2302.00857) will appear at CPAL 2024! 
- Will be joining Amazon.com, Inc. in Seattle as a Research Scientist intern! 
- New preprint: [Non-Convex Bilevel Optimization with Time-Varying Objective Functions](https://arxiv.org/abs/2308.03811)  We study online bilevel optimization where the functions can be time-varying and the agent continuously updates the decisions with online streaming data. 
- New preprint: [Doubly Robust Instance-Reweighted Adversarial Training](https://arxiv.org/abs/2308.00311). We propose a novel doubly robust instance reweighted adversarial training framework based on Distributionally Robust Optimization (DRO).
- Gave an invited talk in the session ‚ÄúBilevel Stochastic Methods for Optimization and Learning‚Äù at the 2022 INFORMS Annual Meeting, Indianapolis, IN. 

